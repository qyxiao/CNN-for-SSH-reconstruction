{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import xarray as xr\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Unet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding = 1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding = 1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding = 1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding = 1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                    torch.nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding = 1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "#                     torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) ## padding?\n",
    "                    )\n",
    "            return  block\n",
    "    \n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding = 1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding = 1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "                    torch.nn.SELU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    )\n",
    "            return  block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNet, self).__init__()\n",
    "        #Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=32)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(32, 64)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=128, out_channels=128, padding = 1),\n",
    "                            torch.nn.SELU(),\n",
    "                            torch.nn.BatchNorm2d(128),\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=128, out_channels=128, padding = 1),\n",
    "                            torch.nn.SELU(),\n",
    "                            torch.nn.BatchNorm2d(128),\n",
    "                            torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=128, out_channels=128, padding = 1),\n",
    "                            torch.nn.SELU(),\n",
    "                            torch.nn.BatchNorm2d(128),\n",
    "                            )\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(256, 128, 64)\n",
    "        self.conv_decode2 = self.expansive_block(128, 64, 32)\n",
    "        self.final_layer = self.final_block(64, 32, out_channel)\n",
    "        \n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        # Decode\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True) ### false should work?\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        return  final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channel = 1, out_channel = 1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vort_0_train = np.load('vort_train.npy')\n",
    "Vort_0_test = np.load('vort_test.npy')\n",
    "\n",
    "Eta_train = np.load('Eta_train.npy')\n",
    "Eta_test = np.load('Eta_test.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The format for input is batch x channel x width x height.\n",
    "## Even though we only have 1 channel, it is still necessary to have an dimension for it.\n",
    "\n",
    "xTrain = np.expand_dims(Eta_train, axis=1)\n",
    "xTest = np.expand_dims(Eta_test, axis=1)\n",
    "\n",
    "yTrain =  np.expand_dims(Vort_0_train, axis=1)\n",
    "yTest =  np.expand_dims(Vort_0_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embed data into pytorch data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_path, y_path):\n",
    "\n",
    "        self.X = torch.from_numpy(X_path).float()\n",
    "        self.y = torch.from_numpy(y_path).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(X_path = xTrain, y_path = yTrain)\n",
    "val_dataset = MyDataset(X_path = xTest, y_path = yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "log_interval = 500\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy = []\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    count = 0\n",
    "    for data, target in val_loader:\n",
    "        count += 1\n",
    "        output = model(data)\n",
    "        validation_loss += F.mse_loss(output, target, reduction='mean').item() # sum up batch loss\n",
    "\n",
    "    validation_loss /= count\n",
    "    print('\\nValidation set: Average loss: {:.4f}\\n'.format(\n",
    "        validation_loss))\n",
    "    validation_accuracy.append(validation_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(16)\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "torch.save(model.state_dict(), './models/vort_cs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load\n",
    "model = UNet(in_channel = 1, out_channel = 1)\n",
    "model.load_state_dict(torch.load('./models/vort_cs'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mitgcm]",
   "language": "python",
   "name": "conda-env-mitgcm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
